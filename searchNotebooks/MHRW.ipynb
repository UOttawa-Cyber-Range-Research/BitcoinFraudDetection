{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f064138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some parameters\n",
    "factor = 150\n",
    "data_dir = \"data/dataset\"\n",
    "save_path = \"data/datasetMHRW\"\n",
    "partitions_dir = \"partitions.parquet\"\n",
    "splits = ['train', 'val', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72bc5b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1288a533-2faf-48a2-8b47-ca1e99676cb7",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "ec54a8d6-b0cd-458d-9798-270a8a81f645",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import deque\n",
    "from pyvis.network import Network\n",
    "from lib.store import Store\n",
    "from tqdm.notebook import tqdm\n",
    "import fsspec\n",
    "from collections import Counter\n",
    "from typing import Dict\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from lib.naming_corrections import (\n",
    "    FEATURE_COLUMNS_OTHERS,\n",
    "    FEATURES_NAMES_FROM_NEW_CACHE,\n",
    "    FEATURES_NAMES_FROM_PRELOADED_CACHE,\n",
    "    TABLES_COLUMNS_DEFAULT_LEGACY,\n",
    "    TABLES_V5_2_V4_RENAME_LEGACY,\n",
    ")\n",
    "\n",
    "FEATURE_COLUMNS = FEATURES_NAMES_FROM_PRELOADED_CACHE + FEATURE_COLUMNS_OTHERS\n",
    "TABLES_V5_2_V4_RENAME = TABLES_V5_2_V4_RENAME_LEGACY\n",
    "TABLES_COLUMNS_DEFAULT = TABLES_COLUMNS_DEFAULT_LEGACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aa2a563-8567-472c-9086-35a620caa79d",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "a348c79b-3202-4ef9-8e49-872d78a5b97d",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "def generic_mhrw_edges(G, source, label_dict, neighbors=None, depth_limit=None, sort_neighbors=None, factor=100):\n",
    "    \"\"\"\n",
    "    Iterate over edges in a MHR search.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the ratio \n",
    "    ratio = {0: 0, 1: 0}\n",
    "    visited = {source}\n",
    "\n",
    "    # Define the depth limit\n",
    "    if depth_limit is None:\n",
    "        depth_limit = len(G)\n",
    "\n",
    "    # No need for a queue\n",
    "    node_list = set()\n",
    "    parent_node = source\n",
    "    parent_neighbors = list(neighbors(source))\n",
    "    node_list.update(parent_neighbors)\n",
    "\n",
    "    # Find the degree of the parent node\n",
    "    degree_parent = G.degree(source)\n",
    "\n",
    "    # Maintain the ratio\n",
    "    ratio[label_dict[source]] += 1\n",
    "\n",
    "    # Placeholder for collected edges\n",
    "    edges = []\n",
    "    set_all_added_nodes = set()\n",
    "\n",
    "    # Define the logic for MHRW\n",
    "    while (ratio[0]/ratio[1]) < factor:\n",
    "        # Check if node list is not empty\n",
    "        if len(node_list) > 0:\n",
    "            # Get the next child\n",
    "            child = node_list.pop()\n",
    "    \n",
    "            # Define the probability\n",
    "            p = round(random.uniform(0, 1), 4)\n",
    "    \n",
    "            # Add nodes and update visited\n",
    "            if child not in visited and label_dict[child] != 1:\n",
    "                # Neighbors of child\n",
    "                child_neighbors = neighbors(child)\n",
    "    \n",
    "                # Collect the degree of the child\n",
    "                degree_child = G.degree(child)\n",
    "    \n",
    "                # Check if probability constraint is satisfied\n",
    "                if (p <= min(1, degree_parent / degree_child) and child in list(neighbors(parent_node))):\n",
    "                    # Update the edges and other list\n",
    "                    edges.append((parent_node, child))\n",
    "\n",
    "                    # Update the global list\n",
    "                    set_all_added_nodes.update((parent_node, child))\n",
    "\n",
    "                    # Uodate the visited and ratio\n",
    "                    visited.add(child)\n",
    "                    ratio[label_dict[child]] += 1\n",
    "                    \n",
    "                    # Replace the data\n",
    "                    parent_node = child\n",
    "                    degree_parent = degree_child\n",
    "                    node_list.clear()\n",
    "                    node_list.update(child_neighbors)\n",
    "\n",
    "        else:\n",
    "            # Update the nodelist with random nodes\n",
    "            node_list.update(set(random.sample(list(set(G.nodes()) - set_all_added_nodes), 3)))\n",
    "            \n",
    "            # Get the new parent\n",
    "            parent_node = node_list.pop()\n",
    "            \n",
    "            # Refresh the node list\n",
    "            degree_parent = G.degree(parent_node)\n",
    "            node_list.clear()\n",
    "            node_list.update(list(neighbors(parent_node)))\n",
    "\n",
    "    # Return the data\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e59ad080-8b60-4461-aa60-54da964f9881",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "c2d8eed3-fe7f-4ad8-8e36-d0f435be37d6",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "def load_local_data_store(data_dir:str) -> Store:   \n",
    "    # build the store\n",
    "    store = Store(\n",
    "        base_dir=data_dir,\n",
    "        protocol='file'\n",
    "    )\n",
    "    return store\n",
    "\n",
    "datastore = load_local_data_store(data_dir)\n",
    "df_p = pd.read_parquet(\n",
    "        datastore.open_file(partitions_dir)\n",
    "    ).reset_index(drop=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b5aad7f-a19d-4e0d-b109-018e35370c7e",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "a7059ad3-9ed8-41c4-931a-e9f39fa5e580",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "counters = {}\n",
    "graph_data = {}\n",
    "labelled = {}\n",
    "others = {}\n",
    "for sp, A in df_p.groupby('split'):\n",
    "    graph_data[sp] = {\n",
    "        x: None\n",
    "        for x in sorted(A['index'])\n",
    "    }\n",
    "    labelled[sp] = {\n",
    "        x: None\n",
    "        for x in sorted(A['index'])\n",
    "    }\n",
    "    counters[sp] = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba361df",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "5301c583-2ae8-481e-ba97-67ab09de6c03",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Scaler...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb344c11a2c40eb9f6132c0892b4dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fit_scaler(graph_data: Dict):\n",
    "    print(\"Fitting Scaler...\")\n",
    "    scaler = MinMaxScaler()\n",
    "    for p in tqdm(graph_data):\n",
    "        df_f = pd.read_parquet(f\"./data/dataset/cache/features/features_{p}.parquet\")\n",
    "        X = df_f[FEATURE_COLUMNS].fillna(value=0.0).values\n",
    "        scaler.partial_fit(X)\n",
    "        del df_f, X\n",
    "        gc.collect()\n",
    "    return scaler\n",
    "\n",
    "scaler = fit_scaler(graph_data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe757ef-dbfa-43cc-b98c-a5cce84b000e",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "7cc2be65-a784-4550-b2ce-e1581cdd3cd0",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4abc614eaa54858afff3802cb1398fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# New parition file\n",
    "p_dict = {'index': [], 'split': []}\n",
    "\n",
    "# Placeholder\n",
    "idx = 0\n",
    "\n",
    "# Loop over splits\n",
    "for sp in splits:\n",
    "\n",
    "    # Loop over split data\n",
    "    bar = tqdm(graph_data[sp])\n",
    "\n",
    "    # Loop over the bar\n",
    "    for p in bar:\n",
    "        # Load the required files\n",
    "        network = pd.read_parquet(f'./{data_dir}/cache/edges/edges_{p}.parquet')\n",
    "        labels = pd.read_parquet(f'./{data_dir}/labels/labels_{p}.parquet')\n",
    "        features = pd.read_parquet(f'./{data_dir}/cache/features/features_{p}.parquet')\n",
    "    \n",
    "        # Convert to network x graph\n",
    "        G = nx.from_pandas_edgelist(network, 'from', 'to')\n",
    "        successors = G.neighbors # can retrieve all neighbors of a particular node with []\n",
    "        \n",
    "        # Replace all label 2 as label 0\n",
    "        labels.loc[labels['label'] == 2, 'label'] = 0\n",
    "        label_dict = dict(zip(labels.node, labels.label))\n",
    "    \n",
    "        # Construct graph from each positive node\n",
    "        for _, pos_node in enumerate(labels[labels['label']==1].node.values):\n",
    "            try: # the node in the label parquet may not exist in the edge parquet\n",
    "                result = generic_mhrw_edges(G, pos_node, label_dict, successors, factor=factor)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "            # Convert the FS seach to dataframe from merging and stuff\n",
    "            df_result = pd.DataFrame(result, columns=['from', 'to'])\n",
    "            \n",
    "            # Undirected to directed\n",
    "            directed1 = network.merge(df_result, how='inner', left_on=['from', 'to'], right_on=['from', 'to'])\n",
    "            directed2 = network.merge(df_result, how='inner', left_on=['from', 'to'], right_on=['to', 'from'])[['from_x', 'to_x', 'partition']].rename(columns={\"from_x\": \"from\", \"to_x\": \"to\", 'partition': 'partition'})\n",
    "            samples = pd.concat([directed1, directed2], axis=0)\n",
    "            edges_list = samples[['from', 'to']].values\n",
    "    \n",
    "            # Get the unique graph edges\n",
    "            df_node = pd.DataFrame(set(edges_list.reshape(-1)), columns=['node'])\n",
    "    \n",
    "            # Process the features and labels\n",
    "            sample_labels = labels.merge(df_node, how='inner').sort_values(by=['node'])\n",
    "            sample_features = features.merge(sample_labels, how='inner', on='txid').sort_values(by=['node']).drop(['node'], axis=1)\n",
    "            mapping = dict(zip(sample_labels.node.values, range(len(sample_labels))))\n",
    "            samples[['from', 'to']] = samples[['from', 'to']].replace(mapping)\n",
    "            sample_labels.node = [i for i in range(len(sample_labels))]\n",
    "            sample_features[FEATURE_COLUMNS] = scaler.transform(sample_features[FEATURE_COLUMNS].values)\n",
    "    \n",
    "            # Save the data\n",
    "            samples.to_parquet(f'./{save_path}/cache/edges/edges_{idx}.parquet')\n",
    "            sample_labels.to_parquet(f'./{save_path}/labels/labels_{idx}.parquet')\n",
    "            sample_features.to_parquet(f'./{save_path}/cache/features/features_{idx}.parquet')\n",
    "    \n",
    "            # New partition deck\n",
    "            p_dict['index'].append(idx)\n",
    "            p_dict['split'].append(sp)\n",
    "    \n",
    "            # Increment the idx\n",
    "            idx += 1\n",
    "\n",
    "            # Set the bar description\n",
    "            bar.set_description(f\"File name : {p} | Saved File Name : {idx}\")\n",
    "\n",
    "        # delete the extra stuff and clear memory\n",
    "        del network, labels, features, G, successors\n",
    "        gc.collect()\n",
    "\n",
    "# Save the parition file\n",
    "pd.DataFrame.from_dict(p_dict).to_parquet(f\"./{save_path}/partitions.parquet\")"
   ]
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

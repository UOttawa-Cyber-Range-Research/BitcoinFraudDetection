{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1141f649-b269-47b6-b23b-c20f83d378bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from copy import deepcopy\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lib.store import Store\n",
    "from lib.naming_corrections import (\n",
    "    FEATURE_COLUMNS_OTHERS,\n",
    "    FEATURES_NAMES_FROM_NEW_CACHE,\n",
    "    FEATURES_NAMES_FROM_PRELOADED_CACHE,\n",
    "    TABLES_COLUMNS_DEFAULT_LEGACY,\n",
    "    TABLES_V5_2_V4_RENAME_LEGACY,\n",
    ")\n",
    "\n",
    "FEATURE_COLUMNS = FEATURES_NAMES_FROM_PRELOADED_CACHE + FEATURE_COLUMNS_OTHERS\n",
    "TABLES_V5_2_V4_RENAME = TABLES_V5_2_V4_RENAME_LEGACY\n",
    "TABLES_COLUMNS_DEFAULT = TABLES_COLUMNS_DEFAULT_LEGACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e24670f4-893a-4a2e-809b-8b5731b92b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_scaler(graph_data, cached_features_dir, datastore):\n",
    "    '''Fit the scalar for each model'''\n",
    "    print (\"Fitting Scaler...\")\n",
    "    scaler = StandardScaler()\n",
    "    for p in tqdm(graph_data):\n",
    "        df_f = pd.read_parquet(\n",
    "                    datastore.open_file(os.path.join(cached_features_dir, f\"features_{p}.parquet\"))\n",
    "                )\n",
    "            \n",
    "        X = df_f[\n",
    "            FEATURE_COLUMNS\n",
    "        ].fillna(value=0.).values\n",
    "        scaler.partial_fit(X)\n",
    "    return scaler\n",
    "\n",
    "def read_from_cache(features_partition_filepath, edges_partition_filepath, datastore):\n",
    "    df_f = pd.read_parquet(\n",
    "        datastore.open_file(features_partition_filepath)\n",
    "    )\n",
    "    df_e = pd.read_parquet(\n",
    "        datastore.open_file(edges_partition_filepath)\n",
    "    )\n",
    "    return df_f, df_e\n",
    "\n",
    "def augment_labels(y, rng, semi_supervised, semi_supervised_resample_negs=None, semi_supervised_resample_factor=None):\n",
    "    '''Augment the labels'''\n",
    "    if semi_supervised == False:\n",
    "        _idx, = np.where(y == 2)\n",
    "        y[_idx] = 0\n",
    "    elif semi_supervised_resample_negs is None:\n",
    "        # dont do anything\n",
    "        pass\n",
    "    elif (\n",
    "        (semi_supervised_resample_negs == 'random')\n",
    "        or\n",
    "        (semi_supervised_resample_negs == 'candidates')\n",
    "    ):\n",
    "        if semi_supervised_resample_negs == 'candidates':\n",
    "            raise NotImplementedError(\"neg-candidates not implemented for loader_v3\")\n",
    "        else:\n",
    "            # randomize the 0 and 2 labels\n",
    "            _idx, = np.where((y == 2) | (y==0))\n",
    "            y[_idx] = 2 # unsup\n",
    "\n",
    "        _n = max((y==1).sum(), 1) # at least 1\n",
    "\n",
    "        for i in rng.choice(\n",
    "            range(len(_idx)),\n",
    "            size=min(\n",
    "                len(_idx), \n",
    "                _n * semi_supervised_resample_factor\n",
    "            ), \n",
    "            replace=False,\n",
    "        ):\n",
    "            y[_idx[i]] = 0 # neg class\n",
    "    return y\n",
    "\n",
    "def load_local_data_store(data_dir):   \n",
    "    # build the store\n",
    "    store = Store(\n",
    "        base_dir=data_dir,\n",
    "        protocol='file'\n",
    "    )\n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a8876c0-7101-4d33-9927-ec92e3a66083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Scaler...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1371522082f64c318a5646c12a98717d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the directories\n",
    "data_dir = \"data/datasetMHRW\"\n",
    "labels_dir = \"labels\"\n",
    "partitions_dir = \"partitions.parquet\"\n",
    "cached_features_dir = \"cache/features\"\n",
    "cached_edges_dir = \"cache/edges\"\n",
    "\n",
    "# Load the datastore\n",
    "datastore = load_local_data_store(data_dir)\n",
    "\n",
    "# Read the partition\n",
    "df_p = pd.read_parquet(\n",
    "    datastore.open_file(partitions_dir)\n",
    ").reset_index(drop=True).reset_index()\n",
    "\n",
    "# Make the counters for selecting the splits\n",
    "counters = {}\n",
    "graph_data = {}\n",
    "labelled = {}\n",
    "for sp, A in df_p.groupby('split'):\n",
    "    graph_data[sp] = {\n",
    "        x: None\n",
    "        for x in sorted(A['index'])\n",
    "    }\n",
    "    labelled[sp] = {\n",
    "        x: None\n",
    "        for x in sorted(A['index'])\n",
    "    }\n",
    "    counters[sp] = Counter()\n",
    "\n",
    "# Fit the scalarA\n",
    "scaler = fit_scaler(graph_data[\"train\"],\n",
    "                    cached_features_dir=cached_features_dir,\n",
    "                    datastore=datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cbb2e5b-c45f-4332-8cea-78a18b06d9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cached Data for Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87777f4611954875b22ac27688d46363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2b0dcbe43e4020809efe723a9fd09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e51d58d607b424c8e7d7b3491680d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Loading Cached Data for Training...\")\n",
    "\n",
    "# Define the splits\n",
    "rng=np.random.default_rng(seed=1)\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# Make the splits for data collection\n",
    "feature_dict = {\"train\" : [], \"val\": [], \"test\": []}\n",
    "label_dict = {\"train\" : [], \"val\": [], \"test\": []}\n",
    "for sp in splits:\n",
    "    for p in tqdm(graph_data[sp]):\n",
    "        # Load the files\n",
    "        labels_partition_filepath = os.path.join(labels_dir, f\"labels_{p}.parquet\")\n",
    "        features_partition_filepath = os.path.join(cached_features_dir, f\"features_{p}.parquet\")\n",
    "        edges_partition_filepath = os.path.join(cached_edges_dir, f\"edges_{p}.parquet\")\n",
    "\n",
    "        # Load the partition\n",
    "        df_l = pd.read_parquet(\n",
    "            datastore.open_file(labels_partition_filepath)\n",
    "        )\n",
    "             \n",
    "        df_f, df_e = read_from_cache(features_partition_filepath,\n",
    "                                     edges_partition_filepath,\n",
    "                                     datastore)\n",
    "\n",
    "        X = df_f[\n",
    "            FEATURE_COLUMNS\n",
    "        ].fillna(value=0.).values\n",
    "\n",
    "        # Scale the values\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "        # need to ensure ordering is same\n",
    "        y = df_f[['txid']].merge(\n",
    "            df_l[['txid', 'label']],\n",
    "        )['label'].values\n",
    "\n",
    "        # uses a negative sampling strategy\n",
    "        y=augment_labels(\n",
    "            y, \n",
    "            rng, \n",
    "            semi_supervised=True, \n",
    "            semi_supervised_resample_negs=None, \n",
    "            semi_supervised_resample_factor=None\n",
    "        )\n",
    "\n",
    "        # Change all labels and find indexes\n",
    "        labelled[sp][p], = np.where(\n",
    "            y != 2\n",
    "        )\n",
    "\n",
    "        # Update the counter\n",
    "        counters[sp].update(y)\n",
    "\n",
    "        # Build the ground Data\n",
    "        feature_dict[sp].append(X)\n",
    "        label_dict[sp].append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5016941-112c-4cad-a7f6-eb5ec91a8ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (2192594, 51)\n",
      "Val shape : (206537, 51)\n",
      "Test shape : (206343, 51)\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "train_X = np.concatenate(feature_dict['train'])\n",
    "train_y = np.concatenate(label_dict['train'])\n",
    "print(f\"Train shape : {train_X.shape}\")\n",
    "\n",
    "# Validation\n",
    "val_X = np.concatenate(feature_dict['val'])\n",
    "val_y = np.concatenate(label_dict['val'])\n",
    "print(f\"Val shape : {val_X.shape}\")\n",
    "\n",
    "# Test\n",
    "test_X = np.concatenate(feature_dict['test'])\n",
    "test_y = np.concatenate(label_dict['test'])\n",
    "print(f\"Test shape : {test_X.shape}\")\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = lgbm.Dataset(train_X, train_y)\n",
    "val_dataset = lgbm.Dataset(val_X, val_y)\n",
    "test_dataset = lgbm.Dataset(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88547532-5a47-412e-9d95-d0cd17a614df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10438, number of negative: 2182156\n",
      "[LightGBM] [Info] Total Bins 11726\n",
      "[LightGBM] [Info] Number of data points in the train set: 2192594, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.004761 -> initscore=-5.342616\n",
      "[LightGBM] [Info] Start training from score -5.342616\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[858]\ttraining's auc: 0.932478\tvalid_1's auc: 0.920817\tvalid_2's auc: 0.913897\n",
      "Model Training Completed.....\n"
     ]
    }
   ],
   "source": [
    "# Define the params\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'is_unbalance': True,\n",
    "    'metric': 'auc',\n",
    "    'is_training_metric': True,\n",
    "    'learning_rate': 1e-3,\n",
    "    'n_jobs': 5,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 1,\n",
    "    'force_col_wise': 'true',\n",
    "    'is_unbalance': 'true'\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model = lgbm.train(params=params,\n",
    "                   num_boost_round=1000,\n",
    "                   train_set=train_dataset,\n",
    "                   valid_sets=[train_dataset, val_dataset, test_dataset],\n",
    "                   callbacks=[lgbm.early_stopping(stopping_rounds=20)])\n",
    "print(\"Model Training Completed.....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c7cd29-f84b-4087-a9f4-3f82b2f66bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_X)\n",
    "y_pred = (y_pred > 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3694a578-6f0c-47ab-8f08-e09e31d85bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[198915   6517]\n",
      " [   429    482]]\n",
      "\n",
      "True Negatives(TN) =  198915\n",
      "\n",
      "True Positives(TP) =  482\n",
      "\n",
      "False Positives(FP) =  6517\n",
      "\n",
      "False Negatives(FN) =  429\n",
      "\n",
      "True Positive Rate =  0.5290889132821076\n",
      "\n",
      "True Negative Rate =  0.9682766073445228\n",
      "\n",
      "bacc =  0.7486827603133153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(test_y, y_pred)\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "print('\\nTrue Negatives(TN) = ', cm[0,0])\n",
    "print('\\nTrue Positives(TP) = ', cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
    "print('\\nTrue Positive Rate = ', cm[1,1] / cm[1].sum())\n",
    "print('\\nTrue Negative Rate = ', cm[0,0] / cm[0].sum())\n",
    "print('\\nbacc = ', ((cm[1,1] / cm[1].sum()) + (cm[0,0] / cm[0].sum()))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3982c3c2-c011-4406-9d98-02ef5ec7fbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      0.97      0.98    205432\n",
      "     class 1       0.07      0.53      0.12       911\n",
      "\n",
      "    accuracy                           0.97    206343\n",
      "   macro avg       0.53      0.75      0.55    206343\n",
      "weighted avg       0.99      0.97      0.98    206343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_y, y_pred, target_names=['class 0', 'class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78ce903b-b4cd-4a21-902b-66c88804aeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score : 0.12187104930467761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"f1-score : {f1_score(test_y, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
